{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('train_essays.csv')\n",
    "development_data = pd.read_csv('development.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def buildVocabulary(texts, occurence=5):\n",
    "    all_text = ' '.join(texts)\n",
    "    words = re.findall(r'\\b\\w+\\b', all_text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    vocabulary = [word for word, count in word_counts.items() if count >= occurence]\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = buildVocabulary(data['text'])\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create Reverse Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseIndex(vocabulary):\n",
    "    reverse_index = {word: index for index, word in enumerate(vocabulary)}\n",
    "    return reverse_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reverseIndex(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Calculate Occurrence Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurrenceProbability(word, all_documents):\n",
    "    total_words = sum(1 for doc in all_documents if word in doc)\n",
    "    total_documents = len(all_documents)\n",
    "    return total_words / total_documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Calculate Conditional Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionalProbability(word, class_documents, all_documents):\n",
    "    total_words = sum(1 for doc in class_documents if word in doc)\n",
    "    total_documents = len(class_documents)\n",
    "    return {word: total_words / total_documents} if total_documents > 0 else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Calculate Conditional Probability with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionalProbabilitySmoothed(word, class_documents, all_documents, vocabulary_size, smoothing_parameter=1):\n",
    "    total_words = sum(1 for doc in class_documents if word in doc)\n",
    "    total_documents = len(class_documents)\n",
    "    return (total_words + smoothing_parameter) / (total_documents + smoothing_parameter * vocabulary_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Predict Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def predict(document, vocabulary, human_occurence, ai_occurence, human_conditional, ai_conditional):\n",
    "    words = re.findall(r'\\b\\w+\\b', document.lower())\n",
    "    probability_human = math.log(human_occurence)\n",
    "    probability_ai = math.log(ai_occurence)\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            conditional_probs_word_human = human_conditional.get(word, 0)\n",
    "            conditional_probs_word_llm = ai_conditional.get(word, 0)\n",
    "            probability_human += math.log(conditional_probs_word_human)\n",
    "            probability_ai += math.log(conditional_probs_word_llm)\n",
    "\n",
    "    return \"0\" if probability_human > probability_ai else \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(dev_documents, dev_labels, vocabulary, human_occurence, ai_occurence, human_conditional, ai_conditional):\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for doc, label in zip(dev_documents, dev_labels):\n",
    "        predicted_class = predict(doc, vocabulary, human_occurence, ai_occurence, human_conditional, ai_conditional)\n",
    "        if predicted_class == label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(dev_documents)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_train = data[data[\"generated\"] == 0][\"text\"].tolist()\n",
    "ai_train = data[data[\"generated\"] == 1][\"text\"].tolist()\n",
    "\n",
    "human_dev_essays = development_data[development_data['generated'] == 0]['text'].tolist()\n",
    "ai_dev_essays = development_data[development_data['generated'] == 1]['text'].tolist()\n",
    "\n",
    "dev_documents = human_dev_essays + ai_dev_essays\n",
    "dev_labels = [\"0\"] * len(human_dev_essays) + [\"1\"] * len(ai_dev_essays)\n",
    "\n",
    "vocabulary = buildVocabulary(human_train + ai_train)\n",
    "\n",
    "human_occurence = occurrenceProbability(\"the\", human_train)\n",
    "ai_occurence = occurrenceProbability(\"the\", ai_train)\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "human_conditional = {word: conditionalProbability(word, human_train, human_train) for word in vocabulary}\n",
    "ai_conditional = {word: conditionalProbability(word, ai_train, ai_train) for word in vocabulary}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_conditional)\n",
    "print(ai_conditional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Compare the Effect of Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_parameters = [0.1, 1, 5, 10]\n",
    "\n",
    "for smoothing_parameter in smoothing_parameters:\n",
    "    conditional_probs_human_smoothed = {word: conditionalProbabilitySmoothed(word, human_train, human_train, vocabulary_size, smoothing_parameter) for word in vocabulary}\n",
    "    conditional_probs_llm_smoothed = {word: conditionalProbabilitySmoothed(word, ai_train, ai_train, vocabulary_size, smoothing_parameter) for word in vocabulary}\n",
    "    accuracy = calculate_accuracy(dev_documents, dev_labels, vocabulary, human_occurence, ai_occurence, conditional_probs_human_smoothed, conditional_probs_llm_smoothed)\n",
    "    print(f\"Smoothing Parameter: {smoothing_parameter}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10: Derive Top 10 Words Predicting Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topWords(class_probability, vocabulary, top_n=10):\n",
    "    sorted_words = sorted(vocabulary, key=lambda word: class_probability[word], reverse=True)\n",
    "    return sorted_words[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_human = topWords(human_conditional, vocabulary)\n",
    "top_words_llm = topWords(ai_conditional, vocabulary)\n",
    "\n",
    "print(\"Top words for Human-generated essays:\", top_words_human)\n",
    "print(\"Top words for AI-generated essays:\", top_words_llm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
